from tokenizer import Tokenizer
import regex as re

with open("taylorswift.txt", 'r') as f:
    text = f.read()
toke = Tokenizer()
toke.train(text, 276)
print(toke.decode([120]))
print(toke.decode(toke.encode("hello world!!!? (ì•ˆë…•í•˜ì„¸ìš”!) lol123 ðŸ˜‰")))

